{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "undefined-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import importlib\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision import models\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import transforms\n",
    "\n",
    "# My libs\n",
    "from core.utils import Stack, ToTorchFormatTensor\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specialized-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unique-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'examples/'\n",
    "mask = 'examples/ssh_examples/'\n",
    "ckpt = 'checkpoints/sttn.pth'\n",
    "model = 'sttn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personal-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w, h = 192, 192\n",
    "# w, h = 432, 240\n",
    "ref_length = 10\n",
    "neighbor_stride = 5\n",
    "default_fps = 24\n",
    "\n",
    "_to_tensors = transforms.Compose([\n",
    "    Stack(),\n",
    "    ToTorchFormatTensor()])\n",
    "\n",
    "\n",
    "# sample reference frames from the whole video \n",
    "def get_ref_index(neighbor_ids, length):\n",
    "    ref_index = []\n",
    "    for i in range(0, length, ref_length):\n",
    "        if not i in neighbor_ids:\n",
    "            ref_index.append(i)\n",
    "    return ref_index\n",
    "\n",
    "\n",
    "# read frame-wise masks \n",
    "def read_mask(mpath):\n",
    "    masks = []\n",
    "    mnames = os.listdir(mpath)\n",
    "    mnames.sort()\n",
    "    for m in mnames: \n",
    "        if 'ipynb' not in m:\n",
    "            m = Image.open(os.path.join(mpath, m))\n",
    "            m = m.resize((w, h), Image.NEAREST)\n",
    "            m = np.array(m.convert('L'))\n",
    "            m = np.array(m > 0).astype(np.uint8)\n",
    "            m = cv2.dilate(m, cv2.getStructuringElement(\n",
    "                cv2.MORPH_CROSS, (3, 3)), iterations=4)\n",
    "            masks.append(Image.fromarray(m*255))\n",
    "    return masks\n",
    "\n",
    "\n",
    "#  read frames from video \n",
    "def read_frame_from_videos(vname):\n",
    "    frames = []\n",
    "    vidcap = cv2.VideoCapture(vname)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(image.resize((w,h)))\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "    return frames       \n",
    "#New\n",
    "def get_ssh_gt():\n",
    "    dataset_path = '../datasets/'\n",
    "    ref_path = dataset_path + 'ref.nc'\n",
    "    xgt = xr.open_dataset(ref_path)\n",
    "    gt = xgt['ssh'].values\n",
    "    gt = gt[:,5:197,5:197]\n",
    "    \n",
    "    maxx = gt.max()\n",
    "    minn = gt.min()\n",
    "    transformed_ssh = (gt-minn)/(maxx-minn) # Ã  revoir\n",
    "    # transformed_ssh =  transformed_ssh[..., np.newaxis]\n",
    "    transformed_ssh = np.stack((transformed_ssh,)*3, axis=1)\n",
    "\n",
    "    # ssh_frames = [Image.fromarray(cv2.cvtColor(transformed_ssh[i], cv2.COLOR_BGR2RGB)) for i in range(len(transformed_ssh))]\n",
    "    \n",
    "    return torch.tensor(transformed_ssh), [transformed_ssh[i].transpose(1,2,0)*255 for i in range(len(transformed_ssh))],(maxx,minn), gt\n",
    "\n",
    "def get_ssh_masks():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "human-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from: checkpoints/sttn.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InpaintGenerator(\n",
       "  (transformer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (query_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (value_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (key_embedding): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (output_linear): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (attention): Attention()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): deconv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): deconv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up models \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = importlib.import_module('model.' + model)\n",
    "model = net.InpaintGenerator().to(device)\n",
    "model_path = ckpt\n",
    "data = torch.load(ckpt, map_location=device)\n",
    "model.load_state_dict(data['netG'])\n",
    "print('loading from: {}'.format(ckpt))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "judicial-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames shape : (192, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "feats, frames, maxmin, gt = get_ssh_gt()\n",
    "print('frames shape :', frames[0].shape)\n",
    "feats = feats.unsqueeze(0)*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "simplified-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = len(frames)\n",
    "\n",
    "frames = [np.array(f).astype(np.uint8) for f in frames]\n",
    "\n",
    "masks = read_mask(mask)\n",
    "binary_masks = [np.expand_dims((np.array(m) != 0).astype(np.uint8), 2) for m in masks]\n",
    "masks = _to_tensors(masks).unsqueeze(0)\n",
    "feats, masks = feats.to(device, dtype=torch.float), masks.to(device, dtype=torch.float)\n",
    "comp_frames = [None]*video_length\n",
    "comp_frames_ssh = [None]*video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Encoding 365 frames into 365 vectors of 256 channels and 48x48 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    feats = model.encoder((feats*(1-masks).float()).view(video_length, 3, h, w))\n",
    "    _, c, feat_h, feat_w = feats.size()\n",
    "    feats = feats.view(1, video_length, c, feat_h, feat_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "driven-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading videos and masks from: examples/\n",
      "feats output : torch.Size([1, 365, 256, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "print('loading videos and masks from: {}'.format(video))\n",
    "print('feats output :',feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mexican-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_reshaped = gt[:,:,:,np.newaxis]\n",
    "maxx, minn = maxmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "closed-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completing holes by spatial-temporal transformers\n",
    "capture_hist = []\n",
    "for f in range(0, video_length, neighbor_stride):\n",
    "    neighbor_ids = [i for i in range(max(0, f-neighbor_stride), min(video_length, f+neighbor_stride+1))]\n",
    "    ref_ids = get_ref_index(neighbor_ids, video_length)\n",
    "    with torch.no_grad():\n",
    "        pred_feat = model.infer(\n",
    "            feats[0, neighbor_ids+ref_ids, :, :, :], masks[0, neighbor_ids+ref_ids, :, :, :])\n",
    "        pred_img = torch.tanh(model.decoder(\n",
    "            pred_feat[:len(neighbor_ids), :, :, :])).detach()\n",
    "        capture_hist.append(pred_img)\n",
    "        pred_img = (pred_img + 1) / 2\n",
    "        pred_img_cpu = pred_img.cpu()\n",
    "        pred_img = pred_img_cpu.permute(0, 2, 3, 1).numpy()*255\n",
    "        pred_ssh = pred_img_cpu.permute(0, 2, 3, 1).numpy().mean(axis=3) # make it gray\n",
    "        pred_ssh = pred_ssh[:,:,:,np.newaxis]\n",
    "        pred_ssh = pred_ssh*(maxx-minn) + minn\n",
    "        \n",
    "        for i in range(len(neighbor_ids)):\n",
    "            idx = neighbor_ids[i]\n",
    "            img = np.array(pred_img[i]).astype(\n",
    "                np.uint8)*binary_masks[idx] + frames[idx] * (1-binary_masks[idx])\n",
    "            img_ssh = pred_ssh[i]*binary_masks[idx] + gt_reshaped[idx] * (1-binary_masks[idx])\n",
    "            \n",
    "            if comp_frames[idx] is None:\n",
    "                comp_frames[idx] = img\n",
    "            else:\n",
    "                comp_frames[idx] = comp_frames[idx].astype(\n",
    "                    np.float32)*0.5 + img.astype(np.float32)*0.5\n",
    "                \n",
    "                \n",
    "            if comp_frames_ssh[idx] is None:\n",
    "                comp_frames_ssh[idx] = img_ssh\n",
    "            else:\n",
    "                comp_frames_ssh[idx] = comp_frames_ssh[idx].astype(\n",
    "                    np.float32)*0.5 + img_ssh.astype(np.float32)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "liquid-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ssh = np.stack(comp_frames_ssh, axis=0)\n",
    "prediction_ssh = prediction_ssh.reshape(video_length, h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "designed-anchor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('prediction10.png',255*prediction_ssh[10])\n",
    "cv2.imwrite('prediction_frame10.png',comp_frames[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse=np.zeros(vide_length)\n",
    "\n",
    "for i in range(0,vide_length):\n",
    "    GT           = gt[i,:200,:200]\n",
    "    pred         = prediction_ssh[i,:200,:200]\n",
    " \n",
    "    nrmse[i]      =  (np.sqrt((GT-pred**2))/np.nanstd(GT)\n",
    "    \n",
    "# plot nRMSE time series\n",
    "N=len(GT)\n",
    "plt.plot(range(N),nrmse_OI,linestyle='solid',color='red',linewidth=2,label=r\"$OI$\")\n",
    "plt.plot(range(N),nrmse_FP_GENN,linestyle='solid',color='seagreen',linewidth=1,label=r\"$FP_GENN$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sttn",
   "language": "python",
   "name": "sttn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
